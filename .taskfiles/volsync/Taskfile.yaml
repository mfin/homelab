---
version: "3"

x-task-env: &task-env
  RSRC: '{{.rsrc}}'
  NAMESPACE: '{{.namespace}}'
  CONTROLLER: '{{.controller}}'
  CLAIM: '{{.claim}}'
  PVC: '{{.pvc}}'
  OFFSET: '{{.offset}}'
  TS: '{{.ts}}'
  POD: '{{.pod}}'

vars:
  destinationTemplate: "{{.ROOT_DIR}}/.taskfiles/volsync/templates/ReplicationDestination.tmpl.yaml"
  wipeJobTemplate: "{{.ROOT_DIR}}/.taskfiles/volsync/templates/WipeJob.tmpl.yaml"
  waitForJobScript: "{{.ROOT_DIR}}/.taskfiles/volsync/scripts/wait-for-job.sh"
  listJobTemplate: "{{.ROOT_DIR}}/.taskfiles/volsync/templates/ListJob.tmpl.yaml"
  attachPvcTemplate: "{{.ROOT_DIR}}/.taskfiles/volsync/templates/AttachPvc.tmpl.yaml"

tasks:
  snapshot:
    desc: Trigger a Restic ReplicationSource snapshot (ex. task v:snapshot rsrc=plex [namespace=default])
    dir: '{{.dir}}'
    vars:
      rsrc: '{{.rsrc | default (base .dir)}}'
    env: *task-env
    cmds:
      - kubectl -n {{.namespace}} patch replicationsources {{.rsrc}} --type merge -p '{"spec":{"trigger":{"manual":"{{.ts}}"}}}'
      - bash {{.waitForJobScript}} volsync-src-{{.rsrc}} {{.namespace}}
      - kubectl -n {{.namespace}} wait job/volsync-src-{{.rsrc}} --for condition=complete --timeout=120m
      # TODO: Error from server (NotFound): jobs.batch "volsync-src-zzztest" not found
      # - kubectl -n {{.namespace}} logs job/volsync-src-{{.rsrc}}
    preconditions:
      - sh: test -f {{.waitForJobScript}}
      - sh: kubectl -n {{.namespace}} get replicationsources {{.rsrc}}
        msg: "ReplicationSource '{{.rsrc}}' not found in namespace '{{.namespace}}'"

  attach:
    desc: Attach a PVC to a Pod for debugging purposes (ex. task v:attach pvc=plex [namespace=default])
    dir: '{{.dir}}'
    vars:
      pvc: '{{.pvc | default (base .dir)}}'
      pod: 'attach-pvc-{{.pvc}}'
    env: *task-env
    cmds:
      - envsubst < <(cat {{.attachPvcTemplate}}) | kubectl apply -f -
      - kubectl wait pods -n {{.namespace}} {{.pod}} --for condition=Ready --timeout=120s
      - kubectl exec -it -n {{.namespace}} {{.pod}} -- bash
      - kubectl delete -n {{.namespace}} pod {{.pod}}

  restore:
    desc: Trigger a Restic ReplicationSource restore (ex. task v:restore rsrc=plex [namespace=default])
    dir: '{{.dir}}'
    vars:
      rsrc: '{{.rsrc | default (base .dir)}}'
      offset: '{{.offset | default 0}}'
      claim:
        sh: |
          kubectl -n {{.namespace}} get replicationsource {{.rsrc}} \
            -o jsonpath="{.spec.sourcePVC}"
      pvc: '{{.pvc | default .claim}}'
      controller:
        sh: |
          app=$(kubectl -n {{.namespace}} get persistentvolumeclaim {{.claim}} -o jsonpath="{.metadata.labels.argocd\.argoproj\.io/instance}")
          if kubectl -n {{ .namespace }} get deployment.dirs/$app >/dev/null 2>&1 ; then
            echo "deployment.apps/$app"
          else
            echo "statefulset.apps/$app"
          fi
    env: *task-env
    cmds:
      - task: restore-suspend-app
        vars:
          rsrc: '{{.rsrc}}'
          controller: '{{.controller}}'
      - task: restore-wipe-job
        vars:
          rsrc: '{{.rsrc}}'
          pvc: '{{.pvc}}'
          claim: '{{.claim}}'
      - task: restore-volsync-job
        vars:
          rsrc: '{{.rsrc}}'
          claim: '{{.claim}}'
          pvc: '{{.pvc}}'
          offset: '{{.offset}}'
      - task: restore-resume-app
    preconditions:
      # - sh: kubectl get -n argocd application {{.name}} -o json | jq -e '.spec.syncPolicy.automated == null'
      #   msg: "Application resource for {{.name}} has syncPolicy.automated defined. Disable it first."
      - sh: test -f {{.wipeJobTemplate}}
      - sh: test -f {{.destinationTemplate}}
      - sh: test -f {{.waitForJobScript}}

  restore-suspend-app:
    internal: true
    cmds:
      - namespace={{.namespace}} name={{.name}} task ac:pause
      - kubectl -n {{.namespace}} scale {{.controller}} --replicas 0
      - kubectl -n {{.namespace}} wait pod --for delete --selector="app.kubernetes.io/name={{.rsrc}}" --timeout=2m

  restore-wipe-job:
    internal: true
    cmds:
      - echo "{{.pvc}} {{.claim}}"
      - envsubst < <(cat {{.wipeJobTemplate}}) | kubectl apply -f -
      - bash {{.waitForJobScript}} wipe-{{.rsrc}}-{{.claim}}-{{.ts}} {{.namespace}}
      - kubectl -n {{.namespace}} wait job/wipe-{{.rsrc}}-{{.claim}}-{{.ts}} --for condition=complete --timeout=120m
      - kubectl -n {{.namespace}} logs job/wipe-{{.rsrc}}-{{.claim}}-{{.ts}} --container wipe
      - kubectl -n {{.namespace}} delete job wipe-{{.rsrc}}-{{.claim}}-{{.ts}}
    env: *task-env

  restore-volsync-job:
    internal: true
    cmds:
      - envsubst < <(cat {{.destinationTemplate}}) | kubectl apply -f -
      - bash {{.waitForJobScript}} volsync-dst-{{.rsrc}}-{{.claim}}-{{.ts}} {{.namespace}}
      - kubectl -n {{.namespace}} wait job/volsync-dst-{{.rsrc}}-{{.claim}}-{{.ts}} --for condition=complete --timeout=120m
      - kubectl -n {{.namespace}} delete replicationdestination {{.rsrc}}-{{.claim}}-{{.ts}}
    env: *task-env

  restore-resume-app:
    internal: true
    cmds:
      - namespace={{.namespace}} name={{.name}} task ac:resume
    env: *task-env
